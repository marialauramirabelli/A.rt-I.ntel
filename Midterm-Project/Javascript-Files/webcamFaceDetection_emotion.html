<!DOCTYPE html>
<html>
  <head>
    <script src="face-api.js"></script>
    <script src="js/commons.js"></script>
    <script src="js/drawing.js"></script>
    <script src="js/faceDetectionControls.js"></script>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
    <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
  </head>
  <body>
    
    <div class="page-container">

      <p class="title1"> EMOTION DETECTOR </p>

      <a href="webcamFaceDetection_reward.html">Happiness Authorities</a>

      <div style="position: relative" class="margin">
        <video onplay="onPlay(this)" id="inputVideo" autoplay muted></video>
        <canvas id="overlay" />
      </div>

      <!-- <div id="results"></div> -->

      <script src="js/webcam.min.js"></script>

    </div>

    <div class="page-container">
     <!--  <p> Message from expression evaluator: </p> -->
      <div class="title3" id="expEv">Waiting for Emotion Evaluation...</div>
      <div class="title3" id="score">Waiting for Social Credit Score...</div>
      <!-- <br><br>
      <p> Message from social credit evaluator: </p>
      <p id="socCredEv"></p>-->
    </div>

    <div class="page-container">
      <div id="my_camera"></div>
      <!--  <p> Query Image: </p> -->

      <div id="query" style="position: relative" class="margin">
        <img id="queryImg" src="" style="max-width: 800px;" />
        <canvas id="queryImgOverlay" class="overlay"/>
      </div>

      <!-- <p> Reference Image: </p> -->

      <!-- <div class="progress" id="loader"> -->
        <!-- <div class="indeterminate"></div> -->
      
      <div id="ref" style="position: relative" class="margin">
        <img id="refImg" src="" style="max-width: 800px;" />
        <canvas id="refImgOverlay" class="overlay"/>
      </div>

     <!--  <p> Expression Image: </p> -->

      <div id="exp" style="position: relative" class="margin">
        <img id="expImg" src="" style="max-width: 800px;" />
        <canvas id="expImgOverlay" class="overlay"/>
      </div>
    </div>
    
    </body>

    <script>
      //VARIABLES//

      //variables from sample code
      let faceMatcher = null
      let thresh = 0.1
      let forwardTimes = []

      //defines whether or not snapshot has been taken/will be retaken
      let snapshotTaken = false;

      //save person identity, social credit score, emotion as objects
      let personInfo;
      let emotionScore = 0;
      let personNum = 1;
      let whichPerson;
      let initialScore;
      let socialCreditScore;
      var newPerson;

      //saves uri of current query image
      let uri;

      const imageList = []

      //saves info for images in database
      var databaseInfo;
      var personREV;
      var personID;

      //FUNCTIONS//

      //retrieves uri data from images in database and saves it in global variable databaseInfo
      function getAllData(){
        $.ajax({
          url: '/api/all',
          type: 'GET',
          dataType: 'json',
          error: function(data){
            //console.log(data);
            alert("Oh No! Try a refresh?");
          },
          success: function(data){
            // console.log("We have data");
            // console.log(data);
            //Clean up the data on the client
            //You could do this on the server
            var theData = data.map(function(d){
              return d.doc;
            });
            databaseInfo = theData;
            console.log("GOT DATA FROM DATABASE!")
            snapshotTaken = false;
            //console.log(theData);
          }
        });
      }

      //tells server to save new person image to database
      function saveData(obj){
        var jsonObj = JSON.stringify(obj);
        $.ajax({
          url: '/save',
          type: 'POST',
          contentType: 'application/json',
          data: jsonObj,
          error: function(resp){
            console.log("Oh no...");
            console.log(resp);
          },
          success: function(resp){
            console.log('WooHoo!');
            console.log("data" +resp);
          }
        });
      }

      //video-related function from sample code
      function updateTimeStats(timeInMs) {
        forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
        const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
        $('#time').val(`${Math.round(avgTimeInMs)} ms`)
        $('#fps').val(`${faceapi.round(1000 / avgTimeInMs)}`)
      }
      Webcam.set({
        width: 320,
        height: 240,
        image_format: 'jpeg',
        jpeg_quality: 90
      });
      Webcam.attach("my_camera");

      //take snapshot and get image data for query image
      function take_snapshot() {
        console.log("TAKE ANOTHER SNAPSHOT NOW")
        Webcam.snap( function(data_uri) {
          uri = data_uri;
          personNum = 1;
          uploadQueryImage(uri);
          checkPersonDatabase();
        });
      }

      //defines interval in which snapshots can be taken (if a person is detected)
      //var intervalID = window.setInterval(resetSnapshot, 30000);
      //resets snapshot boolean to retake snapshot
      function resetSnapshot() {
        if(snapshotTaken){
          getAllData()
          console.log("Snapshot reset");
        }
      }

       //video-related function from sample code
      async function onPlay() {
        const videoEl = $('#inputVideo').get(0)
        if(videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded()){
          return setTimeout(() => onPlay())
        }
        const options = getFaceDetectorOptions()
        const ts = Date.now()
        const result = await faceapi.detectSingleFace(videoEl, options)
        updateTimeStats(Date.now() - ts)
        if (result) {
          drawDetections(videoEl, $('#overlay').get(0), [result])
          //if person is detected, snapshot is taken
          //console.log("PERSON HERE!!!!")
          if(!snapshotTaken){
            take_snapshot();
            snapshotTaken = true;
          }
        }
        // else{
        //   console.log("NO PERSON :(")
        // }
        setTimeout(() => onPlay())
      }

      //goes through uri data that was taken from database and sends data to uploadRefImage;  finds match for query image
      function checkPersonDatabase(){
        uploadRefImage(databaseInfo[personNum - 1].imgString);
        updateResults();

      }

      //assigns an image to the refImg  html img tag (images from database go here)
      async function uploadRefImage(src) {
        $('#refImg').get(0).src = src
      }

      //assigns an image to the queryImg  html img tag (snapshots go here)
      //assigns an image to the expImg  html img tag (snapshots go here)
      async function uploadQueryImage(src) {
        $('#queryImg').get(0).src = src
        //$('#expImg').get(0).src = src
      }

      async function updateResults() {
        console.log("in updateResults")
        await updateReferenceImageResults()
        await updateQueryImageResults()
      }

      async function updateReferenceImageResults() {
        const imgEl = $('#refImg').get(0)
        const canvas = $('#refImgOverlay').get(0)
        const fullFaceDescriptions = await faceapi
          .detectAllFaces(imgEl, getFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceDescriptors()
        if (!fullFaceDescriptions.length) {
          return
        }
        // create FaceMatcher with automatically assigned labels
        // from the detection results for the reference image
        faceMatcher = new faceapi.FaceMatcher(fullFaceDescriptions)
        // resize detection and landmarks in case displayed image is smaller than
        // original size
        resizedResults = resizeCanvasAndResults(imgEl, canvas, fullFaceDescriptions)
        // draw boxes with the corresponding label as text
        const labels = faceMatcher.labeledDescriptors
          .map(ld => ld.label)
        const boxesWithText = resizedResults
          .map(res => res.detection.box)
          .map((box, i) => new faceapi.BoxWithText(box, "Database Image"))
        faceapi.drawDetection(canvas, boxesWithText)
      }

      async function updateQueryImageResults() {
        if (!faceMatcher) {
          return
          console.log("in !faceMatcher")
        }
        //the block of code above blocked this function, for some reason. I think it has to do with faceMatcher as an
        //object. I wasn't sure how to fix it, so I commented it out. It's something we should try to tackle later.
        const imgEl = $('#queryImg').get(0)
        const canvas = $('#queryImgOverlay').get(0)
        const results = await faceapi
          .detectAllFaces(imgEl, getFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceDescriptors()
        // resize detection and landmarks in case displayed image is smaller than
        // original size
        resizedResults = resizeCanvasAndResults(imgEl, canvas, results)
        // draw boxes with the corresponding label as text
        const boxesWithText = resizedResults.map(({ detection, descriptor }) =>
          new faceapi.BoxWithText(
            detection.box,
            // match each face descriptor to the reference descriptor
            // with lowest euclidean distance and display the result as text
            //faceMatcher.findBestMatch(descriptor).toString()
            "Camera Image"
          )
        )
        faceapi.drawDetection(canvas, boxesWithText)

        identifyPerson(resizedResults.map(({ detection, descriptor }) =>
          new faceapi.BoxWithText(
            detection.box,
            // match each face descriptor to the reference descriptor
            // with lowest euclidean distance and display the result as text
            faceMatcher.findBestMatch(descriptor).toString()
          )
        ));
      }

      async function identifyPerson(boxObj){
        //this block of code identifies whether or not the query image is an unknown person. 
        var json = JSON.stringify(boxObj);
        // console.log(boxesWithText);
        var cut = json.substr(2).slice(0,-2);
        var list = cut.split(",");
        for (var i = 0; i < list.length; i++) {
          var smallArray = list[i].split(":");
          if(smallArray[0] != "undefined" && smallArray[1] != "undefined"){
            try{
              smallArray[0] = smallArray[0].substr(1).slice(0,-1);
              smallArray[1] = smallArray[1].substr(1).slice(0,-1);
              smallArray[1] = smallArray[1].split(" ");
            }
            catch(error){
              resetSnapshot();
              break
            }
            if(smallArray[0] == "_text"){
              console.log(smallArray[1][0]);
              if(smallArray[1][0] == "unknown"){
                if(personNum < databaseInfo.length) {
                  personNum += 1;
                  checkPersonDatabase()
                }
                else{
                  newPerson = true;
                  personNum += 1;
                  initialScore = Math.round(700 * detectionAccuracy);
                  var imgObj = {imgString: uri, personNumber: personNum, score: initialScore};
                  saveData(imgObj)
                  // databaseInfo.push({imgString: uri, personNumber: personNum, score: initialScore})
                  $('#expImg').get(0).src = uri
                  updateExpResults()
                }
              }
              else if(smallArray[1][0] == "person"){
                newPerson = false;
                checkPersonNum()
                personNum = whichPerson
                $('#expImg').get(0).src = uri
                updateExpResults()
              }
            }
          }
        }
      }

      //check which person it is
      async function checkPersonNum () {
        const refImgSrc = $('#refImg').get(0).src;
        for (var i = 0; i < databaseInfo.length; i++) {
          if (databaseInfo[i].imgString == refImgSrc) {
            whichPerson = databaseInfo[i].personNumber;
            initialScore = databaseInfo[i].score;
            personREV = databaseInfo[i]._rev;
            personID = databaseInfo[i]._id;
            break
          }
        }
      }
    
      async function updateExpResults() {
        if (!isFaceDetectionModelLoaded()) {
          return
        }
        const inputImgEl = $('#expImg').get(0)
        const options = getFaceDetectorOptions()
        const results = await faceapi.detectAllFaces(inputImgEl, options).withFaceExpressions()
        drawExpressions(inputImgEl, $('#expImgOverlay').get(0), results, thresh, true)
        
        const expressionsEvaluation = results[0].expressions;
        const expressionDetected = expressionsEvaluation[0].expression;
        //assign different emotionScores for each emotion, which influences people's social credit score
        if (expressionDetected == "neutral" || expressionDetected == "surprise") {
          emotionScore = 0;
          document.getElementById("expEv").innerHTML = "PERSON "+personNum+", it's a beautiful day, you should be happier! "+
          "You can do better to boost your Social Credit Score!"
          //document.getElementById("socCredEv").innerHTML = "Person "+personNum+", you're allowed to take one snack for free."
        } else if (expressionDetected == "happy") {
          emotionScore = 10;
          document.getElementById("expEv").innerHTML = "PERSON "+personNum+", you're doing so well! Keep it up! "+
          "You're an inspiration to others, so don't stop spreading happiness around you. :)"
          //document.getElementById("socCredEv").innerHTML = "Person "+personNum+", you're allowed to take two snacks for free."
        } else if (expressionDetected == "scared" || expressionDetected == "sad") {
          emotionScore = -5;
          document.getElementById("expEv").innerHTML = "PERSON "+personNum+", turn that frown upside down! "+
          "Remember, your emotions influence not only those around you, but also your Social Credit Score..."
          //document.getElementById("socCredEv").innerHTML = "Person "+personNum+", you're not allowed to take any free snacks."
        } else if (expressionDetected == "angry" || expressionDetected == "disgusted") {
          emotionScore = -10;
          document.getElementById("expEv").innerHTML = "PERSON "+personNum+", your emotions are unacceptable, what a shame! "+
          "Your Social Credit Score has gone down, but remember, a bright smile can change your day (and your number...)!"
          //document.getElementById("socCredEv").innerHTML = "Person "+personNum+", you're not allowed to take any free snacks "+
          //"and you will be charged an extra fee for any snacks you purchase."
        }
        
        socialCreditScore = initialScore + emotionScore;

        var emotionScoreStr;
        if(emotionScore >= 0){
          emotionScoreStr = "+"+emotionScore;
        }
        else{
          emotionScoreStr = ""+emotionScore;
        }

        document.getElementById("score").innerHTML = "Social Credit Score ("+emotionScoreStr+"): " + socialCreditScore

       if(newPerson == false){
        var imgSrc = $('#refImg').get(0).src
        var scScore = {personID: personID, personREV: personREV, imgString: imgSrc, personNumber: personNum, score: socialCreditScore};
        changeScore(scScore);
        }

        setTimeout(resetSnapshot, 10000);
      }

      function changeScore(obj){
        var jsonObj = JSON.stringify(obj);
        $.ajax({
          //url: '/modifyScore',
          url: '/changeScore',
          type: 'POST',
          contentType: 'application/json',
          data: jsonObj,
          error: function(resp){
            console.log("Oh no...");
            console.log(resp);
          },
          success: function(resp){
            console.log('WooHoo!');
            console.log("data" +resp);
          }
        });
      }

      async function run() {
        // load face detection, face landmark model and face recognition models
        await changeFaceDetector(selectedFaceDetector)
        await faceapi.loadFaceLandmarkModel('/')
        await faceapi.loadFaceRecognitionModel('/')
        await faceapi.loadFaceExpressionModel('/')
        const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
        const videoEl = $('#inputVideo').get(0)
        videoEl.srcObject = stream
      }
      $(document).ready(function() {
        getAllData()
        initFaceDetectionControls()
        run()
      })
    </script>
  </body>
</html>