# RNN FINDINGS  
  
* [Folk RNN](https://folkrnn.org/): website that allows users to generate folk music sheets and corresponding MIDI files, given that "the RNN is trained on transcriptions of folk music."  
**Example** (generated by me): Tune â„–29792 ([MIDI](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/RNN/RNN-Files/folkrnn-tune29792.midi))  
![settings](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/RNN/RNN-Files/folkrnn-settings.JPG)  
![sheet](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/RNN/RNN-Files/folkrnn-sheet.JPG)  
  
* [textgenrnn](https://github.com/minimaxir/textgenrnn): "a Python 3 module on top of Keras/TensorFlow for creating char-rnns" on Google Colabortory.    
**Examples** (generated by me): [Poems](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/RNN/RNN-Files/leavesOfGrass_colaboratory_gentext.txt) "by" Walt Whitman (created by training the model on the complete text for [*Leaves of Grass*](http://www.gutenberg.org/ebooks/1322))  
![whitman](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/RNN/RNN-Files/whitman.JPG) 
And [text](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/RNN/RNN-Files/holmes_colaboratory_gentext.txt) "by" Arthur Conan Doyle (created by training the model on the complete text for [*The Adventures of Sherlock Holmes*](http://www.gutenberg.org/ebooks/1661)) 
![doyle](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/RNN/RNN-Files/doyle.JPG)  
 
* Pixel RNN: I really wanted to try a pixelRNN model, which are used to predict the pixels of a given "incomplete" image in order to complete it (as I understand it). I found a couple of models online (by [philkuz](https://github.com/philkuz/PixelRNN) and [lucko515](https://github.com/lucko515/pixelrnn)), but both are set up to use MNIST as the input data and I wasn't able to quickly figure out how to change the dataset. I ended up not trying to implement them, but I would be interested to do so in the future.  
  
* [Magenta](https://magenta.tensorflow.org/): thought I would give it a go. I tried all the apps in Magenta Studio for one MIDI file (Disney's song "Reflection", downloaded from [MIDIWorld](http://www.midiworld.com/files/)), and [my favorite outputs](https://github.com/marialauramirabelli/A.rt-I.ntel/tree/master/RNN/RNN-Files/Magenta-Continue) were generated by Continue, which "uses the predictive power of recurrent neural networks (RNN) to generate notes that are likely to follow your drum beat or melody." I think this is the case because I can still recognize the original song in these files.
