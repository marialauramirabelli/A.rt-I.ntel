# *(A)rt man(I)festo*
  
Some weeks before the submission of my final project for an undergraduate course on artificial intelligence, taken at New York University Abu Dhabi as part of the Interactive Media program, I reflected on how the class had sparked my interest in the implications, hypotheses, and debates that currently surround AI. The technical aspects of artificial intelligence are certainly fascinating, but discussions about the present and future of AI technology led me to think more critically about our relationship and coexistence, as humans, with this "other" kind of intelligence.
  
Earlier in the semester, my professor had shared an article from *The Atlantic* titled ["The AI-Art Gold Rush Is Here"](https://www.theatlantic.com/technology/archive/2019/03/ai-created-art-invades-chelsea-gallery-scene/584134/) (written by Ian Bogost and published on March 6, 2019), which describes an exhibition of large prints generated by a machine-learning algorithm built over GANs; the work is considered to be a “collaboration between an artificial intelligence named AICAN and its creator, Dr. Ahmed Elgammal”. The reading led to a conversation about the role of technology in art, the meaning and value of art itself, the question of authorship, and the definition of creativity and talent. Inspired by these points and questions, I decided to explore the intersection between AI and art in my final project. 

## Concept
The idea I came up with to address said intersection has two parts: (1) an art manifesto inspired by human creations (existing art manifestos) but generated by artificial intelligence, and (2) a series of artworks that adhere to the manifesto, thus inspired by AI creation but generated by a human (me). I ended up creating five collages that correspond to five sections from the generated manifesto. The images that compose these collages were obtained by and transformed with algorithms also, but curated and arranged by me. And thus, having interwoven the algorithms' work with my own through all stages of the process, the question arises: Is it my work? Is it the algorithms'? Who conceived it, and who controlled it?  
   
## Part I: textgenrnn  
To generate char-rnns and create bodies of text, I used the Python module [textgenrnn](https://github.com/minimaxir/textgenrnn), built on Keras/Tensorflow. The first step to create the art manifesto was to find existing manifestos and artists statement to train the algorithm. This process took some time and required me to make certain "creative" decisions as to what I wanted my final manifesto to be based on. For instance, I found an unexpected amount of Dada manifestos during my research, and made the choice to reject some of them, as I imagined that the word "dada" and other similar ones would otherwise pop up everywhere in the generated text. As another example, I originally included Sir Joshua Reynolds's (1769 - 1790) [*Discourses on Art*](https://www.gutenberg.org/files/2176/2176-h/2176-h.htm) in my data set, but the text was so long compared to others I added that my generated manifesto read like a non-sensical copy of his, exclusively(so I got rid of it in the end). The following are some websites and articles that were extremely useful as sources of text (I found more elsewhere online, but these are great compilations):
* [10 game-changing art manifestos](https://www.royalacademy.org.uk/article/ten-game-changing-manifestos)
* [“Artists who don’t paint aren’t artists”: Top Five Artists’ Manifestos Of All Time](http://www.thedoublenegative.co.uk/2015/10/top-five-artists-manifestos-of-all-time/)
* [Manifestos](https://391.org/manifestos/)
* [8 Artist Statements We Love](http://www.theartleague.org/blog/2015/08/24/artist-statements-we-love/) 
  
Having compiled multiple manifestos and statements in a [txt file](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/Found-Manifestos.txt), I uploaded it to the [Interactive textgenrnn Demo w/ GPU](https://drive.google.com/file/d/1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK/view) (Colaboratory Notebook) and was able to obtain the new manifesto. I went through this process several times, not only to get different versions of the text from the same training data, but because I edited the training data itself (by adding and deleting parts of it, as mentioned above). I chose the [final version](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/Chosen-Manifesto.txt) based on how "authentic" it seemed as an art manifesto (the language is very reminiscent of the manifestos/statements I fed the algorithm) and of it having several sections that could be visually represented. 
  
![manifesto](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/FinalManifesto.jpg)
  
In the image above, the manifesto is presented in a way that juxtaposes the "artificial" with the human, and beyond that, hints at the idea of imitation. The manifesto's text appears in the font Source Code Variable (Adobe), known as a "programming" font, alluding to the machine origin of the text. The first sentence, "Space.", is shown as an image that has been processed with DeepDream (the original background was a galaxy image). However, the frame of the page and the color to highlight sections of the manifesto look like brush strokes, commonly associated to non-digital work, yet these are shapes from the Adobe Illustrator software. Much like the text itself, the strokes pretend to be human-created, even though they are computer-generated.
  
## Part II: Google Search 
With the new manifesto ready, I proceeded to select the sections I wanted to represent. My preference was mostly based on nouns, on how many concrete ones there were; in a manifesto generated from artists' texts, a considerable percentage of the nouns are abstract (unsurprisingly), words along the lines of "soul", "spirit", "space", etc. In this text in particular, the terms "female", "male", and "woman" appear several times, which I believe is courtesy of Valerie Solanas's *SCUM Manifesto* (1967) (which was listed as an art-realted manifesto in a website I browsed, even though that's not its main focus, but I included it in my compilation nevertheless) and Donna Haraways's *A Cyborg Manifesto* (1985) (also listed).

The following are the five chosen sections:
  
![1](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/Sections/text1.JPG)
  
![2](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/Sections/text2.JPG)
  
![3](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/Sections/text3.JPG)
  
![4](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/Sections/text4.JPG)
  
![5](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/Sections/text5.JPG)
  
Once I had specific text to follow, my next step involved none other than Google's search algorithm. My strategy to find the images for the collages was to carry out Google searches with clusters of terms each of the manifesto selections.   
  
For example, for the first section:  
  
![1](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/Sections/text1.JPG)
    
When searching "aesthetic, sense, street" on Google, the eighth image result (at the time I was writing this) was the following:
    
![img](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/ai2.jpg)  
  
## Part III: DeepDream & Neural Style Transfer  
Once the selection of Google images was ready, I used the [deepdream.py](https://github.com/mtyka/deepdream_highres) and [neural_style.py](https://github.com/cysmith/neural-style-tf) Tensorflow implementations to apply DeepDream and style transfer on some of my images. For style transfer specifically, I identified which images could work as content and which could work as style. 
   
For example, for the fourth section:  
  
![4](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/Sections/text4.JPG)
    
The image for "mathematic" (used as style) is the following:
    
![img](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/stylea1.jpg)  
  
And an image for "state, steel" (used as content) is this one:  
  
![img](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/aa4.jpg) 
 
The final result with style transfer (after trying different numbers of iterations when running the code to produce it):  
  
![img](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/resultW.png) 
  
An example of DeepDream, from the same section, comes from the terms "freedom, spirit", which yielded the following result:  
  
![img](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/aa3.jpg) 
  
Applying DeepDream:  
  
![img](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/output.jpg_00008.jpg) 
  
## Part IV: Collage
In this final step, the manipulation and arrangement of the images was entirely up to me, giving me full agency in terms of the creative process. As was pointed out by my professor, though, despite transforming (by cutting and overlapping) and placing the elements of the collage in random and seemingly non-sensical ways, some patterns were ultimately followed that grant meaning to the elements. For instance, in the collage for the fourth section, an image for "parts, sofas" included numbers and text that listed the components of a sofa. This section also has the word "mathematic". Thus, when making the collage, I cut out some of these numbered elements and arranged them in clusters that make "arithmetical" sense (such as 3, 4, and 7, where 3 + 4 = 7). This is, ultimately, what the neural network in textgenrnn did: it followed a process that often produced random and incoherent results, including several nonexistent words (like "disancrete"), but which ultimately adhered quite impressively to the general patterns of the English language. 
  
The final collages are the following:
  
![1](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/Collages/Collage1.jpg)
  
![2](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/Collages/Collage2.jpg)
  
![3](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/Collages/Collage3.jpg)
  
![4](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/Collages/Collage4.jpg)
  
![5](https://github.com/marialauramirabelli/A.rt-I.ntel/blob/master/Final/Collages/Collage5.jpg)
  
For the fifth collage, as is evident, I didn't quite follow the same process as for the rest. For this one, not all the images come the words in the manifesto's section: the background is an image of a sky with clouds altered with DeepDream, the yellow circle is just a shape I made, and the arm in the middle is a photograph of a sculpture by Costa Rican artist Néstor Zeledón titled *Yo protesto* ("I protest" in English), inspired by the phrase "the right to problem" from the manifesto. I really wanted to have more creative input in one of the pieces, and given that the last section was the shortest and most abstract, it was the perfect one to experiment on. 

